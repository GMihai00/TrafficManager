{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1c836c5",
   "metadata": {},
   "source": [
    "https://universe.roboflow.com/pedro-azevedo-3c9ol/bdd100k-3zgda/dataset/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow importlib pandas matplotlib seaborn IPython wget tf_slim lvis tensorflow-io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d684e9ad",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset?select=cars_annos.mat training data used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping images to test\n",
    "from PIL import Image\n",
    "\n",
    "def crop_test_image(image_name: str, xmin: int, ymin: int, xmax: int, ymax: int):\n",
    "    # Load the image\n",
    "    image_path = \".\\\\training_data\\\\standford\\\\cars_test\\\\cars_test\\\\\" + image_name\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Define the bounding box\n",
    "    bbox = (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    # Crop the image using the bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(\".\\\\invalid_cropped_images\\\\\" + image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and convert to json\n",
    "import scipy.io\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_bounding_boxes_from_matlab_file(file_path: str) :\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    annotations = mat['annotations']\n",
    "    \n",
    "    annotations = np.transpose(annotations)\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        bbox_x1 = annotation[0][0][0][0]\n",
    "        bbox_y1 = annotation[0][1][0][0]\n",
    "        bbox_x2 = annotation[0][2][0][0]\n",
    "        bbox_y2 = annotation[0][3][0][0]\n",
    "        fname = annotation[0][4][0]\n",
    "        \n",
    "        #crop_test_image(fname, bbox_x1, bbox_y1, bbox_x2, bbox_y2)\n",
    "        bboxes.append((fname, bbox_x1, bbox_x2, bbox_y1, bbox_y2))\n",
    "    \n",
    "    test_meta = pd.DataFrame(bboxes, columns = ['fnames','bbox_x1', 'bbox_x2', 'bbox_y1', 'bbox_y2'])\n",
    "    \n",
    "    print(test_meta)\n",
    "    return bboxes\n",
    "\n",
    "def get_bounding_boxes_from_matlab_file_train(file_path: str) :\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    annotations = mat['annotations']\n",
    "    \n",
    "    annotations = np.transpose(annotations)\n",
    "    print(annotations)\n",
    "    # print(annotations[0][0][1][0][0])\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        bbox_x1 = annotation[0][0][0][0]\n",
    "        bbox_y1 = annotation[0][1][0][0]\n",
    "        bbox_x2 = annotation[0][2][0][0]\n",
    "        bbox_y2 = annotation[0][3][0][0]\n",
    "        fname = annotation[0][4][0]\n",
    "        \n",
    "        #crop_test_image(fname, bbox_x1, bbox_y1, bbox_x2, bbox_y2)\n",
    "        bboxes.append((fname, bbox_x1, bbox_x2, bbox_y1, bbox_y2))\n",
    "    \n",
    "    test_meta = pd.DataFrame(bboxes, columns = ['fnames','bbox_x1', 'bbox_x2', 'bbox_y1', 'bbox_y2'])\n",
    "    \n",
    "    print(test_meta)\n",
    "    return bboxes\n",
    "    \n",
    "\n",
    "def save_to_coco_json(data_vec, image_dir: str, json_file: str):\n",
    "    categories = [\n",
    "        {'id': 1, 'name': 'Car'}\n",
    "    ]\n",
    "    # Initialize the data dictionary\n",
    "    data = {'images': [], 'annotations': [], 'categories': categories}\n",
    "    \n",
    "    counter = 1\n",
    "    for elem in data_vec:\n",
    "        image_id = elem[0].split('.')[0]\n",
    "\n",
    "        annotation = {\n",
    "                'id': counter,\n",
    "                'image_id': int(image_id),\n",
    "                'category_id': 1,\n",
    "                'bbox': [int(elem[1]), int(elem[2]), int(elem[3]), int(elem[4])],\n",
    "                'area': int((elem[4] - elem[1]) * (elem[3] - elem[2])),\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "        data['annotations'].append(annotation)\n",
    "        counter += 1\n",
    "    \n",
    "    # Add the images to the data dictionary\n",
    "    for annotation in data['annotations']:\n",
    "        if annotation['image_id'] not in [image['id'] for image in data['images']]:\n",
    "            \n",
    "            image = Image.open(image_dir + \"\\\\\" + \"{0:05d}\".format(annotation['image_id']) + '.jpg')\n",
    "            width, height = image.size\n",
    "            data['images'].append({\n",
    "                'id': annotation['image_id'],\n",
    "                'file_name': \"{0:05d}\".format(annotation['image_id']) + '.jpg',\n",
    "                'height': int(height), \n",
    "                'width': int(width) \n",
    "            })\n",
    "    \n",
    "    # Save the data dictionary as JSON\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "test_file = os.path.abspath(\".\\\\training_data\\\\standford\\\\cars_test_annos.mat\")\n",
    "test_img_dir = os.path.abspath(\".\\\\training_data\\\\standford\\\\cars_test\\\\cars_test\")\n",
    "# train_file = os.path.abspath(\".\\\\training_data\\\\standford\\\\cars_train_annos.mat\")\n",
    "# train_img_dir = os.path.abspath(\".\\\\training_data\\\\standford\\\\cars_train\\\\cars_train\")\n",
    "\n",
    "test_data = get_bounding_boxes_from_matlab_file(test_file)\n",
    "# train_data = get_bounding_boxes_from_matlab_file_train(train_file)\n",
    "\n",
    "# coco_json_train = os.path.abspath(\".\\\\training_data\\\\standford\\\\coco_train_standford.json\")\n",
    "coco_json_test = os.path.abspath(\".\\\\training_data\\\\standford\\\\coco_test_standford.json\")\n",
    "\n",
    "save_to_coco_json(test_data, test_img_dir, coco_json_test)\n",
    "# save_to_coco_json(train_data, train_img_dir, coco_json_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "871c6256",
   "metadata": {},
   "source": [
    "https://github.com/udacity/self-driving-car/tree/master/annotations#download training data used(outdated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca984f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "train_directory_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\train'\n",
    "evaluate_directory_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\evaluate'\n",
    "test_directory_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\test'\n",
    "\n",
    "label_file_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\labels\\\\labels.csv'\n",
    "\n",
    "train_label_file_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\labels\\\\train_labels.csv'\n",
    "evaluate_label_file_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\labels\\\\evaluate_labels.csv'\n",
    "test_label_file_path = 'C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\labels\\\\test_labels.csv'\n",
    "\n",
    "train_filenames = set(os.listdir(train_directory_path))\n",
    "evaluate_filenames = set(os.listdir(evaluate_directory_path))\n",
    "test_filenames = set(os.listdir(test_directory_path))\n",
    "\n",
    "with open(label_file_path, 'r') as csv_file, \\\n",
    "    open(train_label_file_path, 'w', newline='') as train_output_file, \\\n",
    "    open(evaluate_label_file_path, 'w', newline='') as evaluate_output_file, \\\n",
    "    open(test_label_file_path, 'w', newline='') as test_output_file:\n",
    "    \n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    header = next(csv_reader)\n",
    "    \n",
    "    train_csv_writer = csv.writer(train_output_file)\n",
    "    train_csv_writer.writerow(header)\n",
    "    evaluate_csv_writer = csv.writer(evaluate_output_file)\n",
    "    evaluate_csv_writer.writerow(header)\n",
    "    test_csv_writer = csv.writer(test_output_file)\n",
    "    test_csv_writer.writerow(header)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if any(filename in row[4] for filename in train_filenames):\n",
    "            train_csv_writer.writerow(row)\n",
    "            \n",
    "        if any (filename in row[4] for filename in evaluate_filenames):\n",
    "            evaluate_csv_writer.writerow(row)\n",
    "        \n",
    "        if any (filename in row[4] for filename in test_filenames):\n",
    "            test_csv_writer.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nevoie de python 3.9\n",
    "def write_label_map(label_map, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for id, name in label_map.items():\n",
    "            f.write('item {\\n')\n",
    "            f.write('  id: {}\\n'.format(id))\n",
    "            f.write(\"  name: '{}'\\n\".format(name))\n",
    "            f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    1: 'Car',\n",
    "    2: 'Truck'\n",
    "}\n",
    "\n",
    "write_label_map(label_map, '.\\\\training_data\\\\labels\\\\coco_labels.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6dfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping images to test\n",
    "from PIL import Image\n",
    "\n",
    "def crop_image(image_name: str, xmin: int, ymin: int, xmax: int, ymax: int):\n",
    "    # Load the image\n",
    "    image_path = \".\\\\training_data\\\\object-detection-crowdai\\\\\" + image_name\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Define the bounding box\n",
    "    bbox = (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    # Crop the image using the bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(\".\\\\invalid_cropped_images\\\\\" + image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98beacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV TO COCO JSON\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "threshold = 160 * 160;\n",
    "\n",
    "def generate_coco_file_from_csv(csv_file: str, json_file: str):\n",
    "    ignore_labels = [\"Pedestrian\"]\n",
    "    # Define the categories\n",
    "    categories = [\n",
    "        {'id': 1, 'name': 'Car'},\n",
    "        {'id': 2, 'name': 'Truck'}\n",
    "    ]\n",
    "    \n",
    "    # Initialize the data dictionary\n",
    "    data = {'images': [], 'annotations': [], 'categories': categories}\n",
    "    \n",
    "    # Read the CSV file and add annotations to the data dictionary\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        counter = 1  # Initialize the counter variable\n",
    "        for row in reader:\n",
    "            if row[\"Label\"] in ignore_labels:\n",
    "                continue\n",
    "            \n",
    "            image_id = int(row['Frame'].split('.')[0])\n",
    "            category_id = 0\n",
    "            for category in categories:\n",
    "                if row['Label'] == category['name']:\n",
    "                    category_id = category['id']\n",
    "                    break\n",
    "    \n",
    "            annotation = {\n",
    "                'id': counter,\n",
    "                'image_id': image_id,\n",
    "                'category_id': category_id,\n",
    "                'bbox': [int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])],\n",
    "                'area': ((int(row['xmax']) - int(row['xmin'])) * (int(row['ymax']) - int(row['ymin']))),\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            \n",
    "            #if annotation['area'] > threshold:\n",
    "                # try:\n",
    "                #     crop_image(row['Frame'], int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax']))\n",
    "                # except:\n",
    "                #     pass\n",
    "                \n",
    "            data['annotations'].append(annotation)\n",
    "            counter +=1\n",
    "\n",
    "    # Add the images to the data dictionary\n",
    "    for annotation in data['annotations']:\n",
    "        if annotation['image_id'] not in [image['id'] for image in data['images']]:\n",
    "            \n",
    "            image = Image.open('.\\\\training_data\\\\object-detection-crowdai\\\\' + str(annotation['image_id']) + '.jpg')\n",
    "            width, height = image.size\n",
    "            \n",
    "            data['images'].append({\n",
    "                'id': annotation['image_id'],\n",
    "                'file_name': str(annotation['image_id']) + '.jpg',\n",
    "                'height': int(width), \n",
    "                'width': int(height) \n",
    "            })\n",
    "\n",
    "    # Save the data dictionary as JSON\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "train_csv_file = '.\\\\training_data\\\\labels\\\\train_labels.csv'\n",
    "train_json_file = '.\\\\training_data\\\\labels\\\\train_coco.json'\n",
    "eval_csv_file = '.\\\\training_data\\\\labels\\\\evaluate_labels.csv'\n",
    "eval_json_file = '.\\\\training_data\\\\labels\\\\evaluate_coco.json'\n",
    "test_csv_file = '.\\\\training_data\\\\labels\\\\test_labels.csv'\n",
    "test_json_file = '.\\\\training_data\\\\labels\\\\test_coco.json'\n",
    "\n",
    "generate_coco_file_from_csv(train_csv_file, train_json_file)\n",
    "generate_coco_file_from_csv(eval_csv_file, eval_json_file)\n",
    "generate_coco_file_from_csv(test_csv_file, test_json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72213bac",
   "metadata": {},
   "source": [
    "Setup repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc .\\object_detection\\protos\\*.proto --python_out=.\n",
    "!cp object_detection\\packages\\tf2\\setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pyperclip\n",
    "\n",
    "original_dir = os.getcwd()  # get the original directory\n",
    "\n",
    "try:    \n",
    "    os.chdir(\".\\\\tf_repo\\\\models\\\\research\\\\object_detection\\\\dataset_tools\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e.strerror}\")\n",
    "    \n",
    "\n",
    "def delete_all_file_inside_folder(folder_path: str):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file: {file_path}. {e}\")\n",
    "        \n",
    "train_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\train'\n",
    "val_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\evaluate'\n",
    "test_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\test'\n",
    "train_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\train_coco.json'\n",
    "val_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\evaluate_coco.json'\n",
    "testdev_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\test_coco.json'\n",
    "output_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\setup_files'\n",
    "label_map_path = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\coco_labels.pbtxt'\n",
    "\n",
    "cmd = [\n",
    "    'python', 'create_coco_tf_record.py', '--logtostderr', \n",
    "    f'--train_image_dir={train_image_dir}', \n",
    "    f'--val_image_dir={val_image_dir}',\n",
    "    f'--test_image_dir={test_image_dir}',\n",
    "    f'--train_annotations_file={train_annotations_file}',\n",
    "    f'--val_annotations_file={val_annotations_file}',\n",
    "    f'--testdev_annotations_file={testdev_annotations_file}',\n",
    "    f'--output_dir={output_dir}',\n",
    "    f'--label_map_path={label_map_path}'\n",
    "]\n",
    "#run before cd .\\\\tf_repo\\\\models\\\\research\\\\object_detection\\\\dataset_tools\n",
    "cmd = f\"python create_coco_tf_record.py --logtostderr --train_image_dir=\\\"{train_image_dir}\\\" --val_image_dir=\\\"{val_image_dir}\\\" --test_image_dir=\\\"{test_image_dir}\\\" --train_annotations_file=\\\"{train_annotations_file}\\\" --val_annotations_file=\\\"{val_annotations_file}\\\" --testdev_annotations_file=\\\"{testdev_annotations_file}\\\" --output_dir=\\\"{output_dir}\\\" --label_map_path=\\\"{label_map_path}\\\"\"\n",
    "\n",
    "pyperclip.copy(cmd)\n",
    "print('Command copied to clipboard.')\n",
    "\n",
    "#cleanup\n",
    "delete_all_file_inside_folder(output_dir)\n",
    "# subprocess.call(\".\\\\tenserflow_env\\\\Scripts\\\\activate.bat && \" + cmd, shell=True)\n",
    "# result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "os.chdir(original_dir)\n",
    "# if result.returncode == 0:\n",
    "#     print(result.stdout)\n",
    "# else:\n",
    "#     print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to check types inside coco file\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# original_dir = os.getcwd()  # get the original directory\n",
    "\n",
    "# try:    \n",
    "#     os.chdir(\".\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\\\setup_files\")\n",
    "# except OSError as e:\n",
    "#     print(f\"Error: {e.strerror}\")\n",
    "    \n",
    "# nr_files = 50; #to change\n",
    "\n",
    "# # Define the file pattern and the output file name\n",
    "# file_pattern = \"coco_testdev.record-000{}-of-000{}\"\n",
    "# output_file = \"merged.tfrecord\"\n",
    "\n",
    "# # Create a list of file names that match the pattern\n",
    "# file_names = [file_pattern.format(str(i).zfill(2), nr_files) for i in range(nr_files)]\n",
    "\n",
    "# filenames = tf.data.Dataset.list_files(file_names)\n",
    "\n",
    "# # Create a TFRecordDataset from your file(s)\n",
    "# dataset = tf.data.TFRecordDataset(file_names)\n",
    "\n",
    "# dataset = filenames.interleave(\n",
    "#     lambda filename: tf.data.TFRecordDataset(filename),\n",
    "#     cycle_length=4,\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# )\n",
    "\n",
    "# print(len(file_names))\n",
    "# print(tf.data.experimental.cardinality(dataset).numpy())\n",
    "\n",
    "\n",
    "    \n",
    "# features = {\n",
    "#     'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "#     'image/object/image_id': tf.io.VarLenFeature(tf.int64),\n",
    "#     'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "#     'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "#     'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "#     'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "#     'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "#     'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "#     'image/object/area': tf.io.VarLenFeature(tf.float32)\n",
    "# }\n",
    "\n",
    "# # Define a function to parse a single example, labels are inside coco file\n",
    "# def parse_function(serialized_example):\n",
    "#     example = tf.io.parse_single_example(serialized_example, features)\n",
    "#     example['image/source_id'] = example['image/object/image_id']\n",
    "#     del example['image/object/image_id']\n",
    "#     return example\n",
    "\n",
    "\n",
    "# def parse_tfrecord(example_proto):\n",
    "#     parsed_example = tf.io.parse_single_example(example_proto, features)\n",
    "#     parsed_example['image/source_id'] = parsed_example['image/object/image_id']\n",
    "#     del parsed_example['image/object/image_id']\n",
    "    \n",
    "#     image = tf.io.decode_jpeg(parsed_example['image/encoded'], channels=3)\n",
    "#     label = {\n",
    "#         'bbox': tf.stack([parsed_example['image/object/bbox/ymin'].values,\n",
    "#                         parsed_example['image/object/bbox/xmin'].values,\n",
    "#                         parsed_example['image/object/bbox/ymax'].values,\n",
    "#                         parsed_example['image/object/bbox/xmax'].values], axis=-1),\n",
    "#         'classes': parsed_example['image/object/class/label'].values\n",
    "#     }\n",
    "#     return image, label\n",
    "\n",
    "\n",
    "# def check_if_dataset_is_ok(dataset):\n",
    "#     parsed_dataset = dataset.map(parse_tfrecord)\n",
    "    \n",
    "#     # load and display the first image and label\n",
    "#     for image, label in parsed_dataset:\n",
    "#         # display the image\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.imshow(image.numpy())\n",
    "#         plt.show()\n",
    "        \n",
    "#         # display the label\n",
    "#         print(label)\n",
    "\n",
    "# #uncomment to verify validity\n",
    "# #check_if_dataset_is_ok(dataset)\n",
    "\n",
    "# os.chdir(original_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f547cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merge coco record files\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# original_dir = os.getcwd()  # get the original directory\n",
    "\n",
    "# try:    \n",
    "#     os.chdir(\".\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\\\setup_files\")\n",
    "# except OSError as e:\n",
    "#     print(f\"Error: {e.strerror}\")\n",
    "    \n",
    "# with tf.io.TFRecordWriter(output_file) as writer:\n",
    "#         parsed_dataset = dataset.map(parse_function)\n",
    "        \n",
    "#         cnt = 1\n",
    "#         for elem in parsed_dataset:\n",
    "#             example = tf.train.Example()\n",
    "#             for key in elem.keys():\n",
    "#                 if elem[key].dtype == tf.string:\n",
    "#                     example.features.feature[key].bytes_list.value.extend([elem[key].numpy()])\n",
    "#                 elif elem[key].dtype in [tf.float32, tf.float64]:\n",
    "#                     example.features.feature[key].float_list.value.extend(tf.sparse.to_dense(elem[key]).numpy())\n",
    "#                 elif elem[key].dtype == tf.int16:\n",
    "#                     if (hasattr(elem[key].numpy(), '__iter__')):\n",
    "#                         for value in elem[key].numpy():\n",
    "#                             example.features.feature[key].int64_list.value.append(value)\n",
    "#                     else:\n",
    "#                         example.features.feature[key].int64_list.value.append(elem[key].numpy())\n",
    "        \n",
    "#             serialized = example.SerializeToString()\n",
    "#             writer.write(serialized)\n",
    "#             print(f'{cnt} item')\n",
    "#             cnt+=1\n",
    "            \n",
    "# os.chdir(original_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check that the files were merged the right\n",
    "import tensorflow as tf\n",
    "\n",
    "original_dir = os.getcwd()  # get the original directory\n",
    "\n",
    "try:    \n",
    "    os.chdir(\".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\setup_files\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e.strerror}\")\n",
    "    \n",
    "merged_file = 'merged.tfrecord'\n",
    "#merged_file = 'coco_testdev.record-00001-of-00050'\n",
    "# Create a TFRecordDataset from the merged file\n",
    "\n",
    "for record in tf.data.TFRecordDataset(merged_file):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "\n",
    "    print(example.features.feature.keys())\n",
    "    \n",
    "os.chdir(original_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c48c9e6a",
   "metadata": {},
   "source": [
    "To check if CUDA and cuDNN installed the right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfef735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # set to the index of the NVIDIA GPU you want to use\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0813b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cuda_dir = os.environ['CUDA_DIR']\n",
    "print(cuda_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04beff2b",
   "metadata": {},
   "source": [
    "Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61364c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "original_dir = os.getcwd()  # get the original directory\n",
    "\n",
    "absolute_label_map_path = os.path.abspath(\".\\\\training_data\\\\labels\\\\coco_labels.pbtxt\")\n",
    "\n",
    "\n",
    "print(f'Label map path: {absolute_label_map_path}')\n",
    "absolute_tfrecord_path = os.path.abspath(\".\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\\\setup_files\\\\coco_testdev.record-000??-of-00050\")\n",
    "print(f'Tfrecord path: {absolute_tfrecord_path}')\n",
    "\n",
    "try:\n",
    "    os.chdir(\"C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\tf_repo\\\\models\\\\research\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e.strerror}\")\n",
    "from object_detection.utils import config_util \n",
    "\n",
    "\n",
    "# https://github.com/udacity/self-driving-car/tree/master/annotations#download training data used\n",
    "MODEL_DIR = os.path.abspath(\"..\\\\..\\\\..\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\")\n",
    "PIPELINE_PATH = os.path.abspath(\"..\\\\..\\\\..\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\\\pipeline.config\")\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_PATH)\n",
    "\n",
    "\n",
    "def find_key_path(key, json_obj, path=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively search for a key in a JSON object and return its path.\n",
    "    \"\"\"\n",
    "    if isinstance(json_obj, dict):\n",
    "        for k, v in json_obj.items():\n",
    "            if k == key:\n",
    "                return f\"{path}/{k}\"\n",
    "            else:\n",
    "                result = find_key_path(key, v, f\"{path}/{k}\")\n",
    "                if result:\n",
    "                    return result\n",
    "    elif isinstance(json_obj, list):\n",
    "        for i, v in enumerate(json_obj):\n",
    "            result = find_key_path(key, v, f\"{path}/{i}\")\n",
    "            if result:\n",
    "                return result\n",
    "\n",
    "\n",
    "\n",
    "#need to change them manually sadly\n",
    "# config['train_input_reader']['tf_record_input_reader']['input_path'] = absolute_tfrecord_path\n",
    "\n",
    "# config['eval_input_reader']['label_map_path'] = absolute_label_map_path\n",
    "# config['eval_input_reader']['tf_record_input_reader']['input_path'] = absolute_tfrecord_path\n",
    "# config['train_config']['fine_tune_checkpoint'] = \".\\\\models\\\\faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\\\\checkpoint\\\\checkpoint\"\n",
    "\n",
    "#saving json \n",
    "with open('C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\config_file.config', 'w') as f:\n",
    "    print(config, file=f)\n",
    "    \n",
    "print(config)\n",
    "\n",
    "os.chdir(original_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a1896ca",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98639e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy object_detection/packages/tf2/setup.py and run python -m pip install . to setup the repo\n",
    "#change dir to cd \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\"\n",
    "import os\n",
    "import pyperclip\n",
    "print(os.getcwd())\n",
    "script = os.path.abspath(\".\\\\tf_repo\\\\models\\\\research\\\\object_detection\\\\model_main_tf2.py\")\n",
    "MODEL_DIR = os.path.abspath(\".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\")\n",
    "PIPELINE_PATH = os.path.abspath(\".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\pipeline.config\")\n",
    "nr_steps = 3000 # can be changed\n",
    "command = \"python \\\"{}\\\"  --model_dir=\\\"{}\\\" --pipeline_config_path=\\\"{}\\\"  --num_train_steps={}\".format(script, MODEL_DIR, PIPELINE_PATH, nr_steps)\n",
    "\n",
    "print(command)\n",
    "pyperclip.copy(command)\n",
    "#run this inside your own cmd\n",
    "#!{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71aa2980",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59040114",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python \\\"{}\\\"  --model_dir=\\\"{}\\\" --pipeline_config_path=\\\"{}\\\"  --checkpoint_dir=\\\"{}\\\"\".format(script, MODEL_DIR, PIPELINE_PATH, MODEL_DIR)\n",
    "\n",
    "print(command)\n",
    "pyperclip.copy(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51933f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to monitor progress\n",
    "import pyperclip\n",
    "command = \"tensorboard --logdir='{}'\".format(MODEL_DIR)\n",
    "\n",
    "print(command)\n",
    "pyperclip.copy(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62085f8b",
   "metadata": {},
   "source": [
    "Freeze the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "base_folder = MODEL_DIR + \"\\\\exports\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "OUTPUT_DIR = f\"{base_folder}_{timestamp}\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "    print(f\"Created folder: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {OUTPUT_DIR}\")\n",
    "\n",
    "script = os.path.abspath(\".\\\\tf_repo\\\\models\\\\research\\\\object_detection\\\\exporter_main_v2.py\")\n",
    "\n",
    "command = \"python \\\"{}\\\"  --input_type=image_tensor --pipeline_config_path=\\\"{}\\\"  --trained_checkpoint_dir=\\\"{}\\\" --output_directory=\\\"{}\\\"\".format(script, PIPELINE_PATH, MODEL_DIR, OUTPUT_DIR)\n",
    "\n",
    "print(command)\n",
    "pyperclip.copy(command)\n",
    "\n",
    "#!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_DIR = \".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\"\n",
    "PATH_TO_SAVED_MODEL= OUTPUT_DIR + \"\\\\saved_model\"\n",
    "print('Loading model...', end='')\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "print('Done!')\n",
    "\n",
    "#Loading the label_map\n",
    "category_index=label_map_util.create_category_index_from_labelmap(\"C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\MLDataTraining\\\\Python\\\\Tensorflow\\\\training_data\\\\BDD100K\\\\train\\\\cars-pedestrians_label_map.pbtxt\",use_display_name=True)\n",
    "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "def merge_boxes(box1, box2):\n",
    "    # box: [ymin, xmin, ymax, xmax]\n",
    "    ymin = min(box1[0], box2[0])\n",
    "    xmin = min(box1[1], box2[1])\n",
    "    ymax = max(box1[2], box2[2])\n",
    "    xmax = max(box1[3], box2[3])\n",
    "    return [ymin, xmin, ymax, xmax]\n",
    "    \n",
    "def detect_objects_inside_image(image_np):\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    car_indices = detections['detection_classes'] == 1\n",
    "    car_boxes = detections['detection_boxes'][car_indices]\n",
    "    car_scores = detections['detection_scores'][car_indices]\n",
    "    \n",
    "    # Perform non-maximum suppression\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        np.array(car_boxes).astype(np.int32),\n",
    "        np.array(car_scores),\n",
    "        score_threshold=0.4,\n",
    "        nms_threshold=0.5\n",
    "    ).flatten()\n",
    "    \n",
    "    # Merge overlapping boxes and get highest score\n",
    "    #merged_box, highest_score = merge_boxes(car_boxes, car_scores, indices)\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "\n",
    "    for i in indices:\n",
    "        print(car_boxes[i])\n",
    "        print(car_scores[i])\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'][indices],\n",
    "        detections['detection_classes'][indices],\n",
    "        detections['detection_scores'][indices],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=.80, # Adjust this value to set the minimum probability boxes to be classified as True\n",
    "        agnostic_mode=False)\n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    plt.show()\n",
    "\n",
    "# Open a video file\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\Mihai Gherghinescu\\\\source\\\\repos\\\\TrafficManager\\\\resources\\\\TestData\\\\CarTestVideo2.mp4\")\n",
    "\n",
    "# # Check if the video file was opened successfully\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error opening video file\")\n",
    "\n",
    "# DELAY = 25\n",
    "\n",
    "# cnt = 0\n",
    "# # Read frames from the video file\n",
    "# while cap.isOpened():\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Check if the frame was read successfully\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     if (cnt == 0):\n",
    "#         image_np = np.array(frame)\n",
    "#         detect_objects_inside_image(image_np)\n",
    "#     # Display the frame\n",
    "\n",
    "#     cnt = (cnt + 1) % DELAY\n",
    "#     # Wait for 25ms and check if the user pressed the 'q' key\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture object and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# def load_image_into_numpy_array(path):\n",
    "\n",
    "#     return np.array(cv2.imread(path))\n",
    "\n",
    "image_path = \".\\\\output.jpg\"\n",
    "detect_objects_inside_image(cv2.imread(image_path))\n",
    "# #print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "# image_np = load_image_into_numpy_array(image_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367b3c00",
   "metadata": {},
   "source": [
    "Export model for c++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from re import match\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "import numpy as np\n",
    "#path of the directory where you want to save your model\n",
    "frozen_out_path = ''\n",
    "# name of the .pb file\n",
    "frozen_graph_filename = 'graph_frozen_Test'\n",
    "\n",
    "OUTPUT_DIR = \".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\"\n",
    "PATH_TO_SAVED_MODEL= OUTPUT_DIR + \"\\\\saved_model\"\n",
    "\n",
    "loaded = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "infer = loaded.signatures['serving_default']\n",
    "\n",
    "full_model = tf.function(infer).get_concrete_function(input_tensor=tf.TensorSpec(shape=[1, None, None, 3], dtype=tf.uint8))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "\n",
    "extract_names = lambda x: x.name\n",
    "\n",
    "# fara input_control_node si output_control_node\n",
    "input_layers = list(filter(lambda v: match('.*input.*', v.name) and 'input_control_node' not in v.name, graph_def.node))\n",
    "\n",
    "output_layers = list(filter(lambda v: match('.*output.*', v.name) and 'output_control_node' not in v.name, graph_def.node))\n",
    "\n",
    "input_layer_names = list(map(extract_names, input_layers))\n",
    "output_layer_names = list(map(extract_names, output_layers))\n",
    "\n",
    "print(\"Input layers: \")\n",
    "print([n for n in input_layer_names])\n",
    "print(\"Output layers: \")\n",
    "print([n for n in output_layer_names])\n",
    "\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              input_layer_names,\n",
    "                                                              output_layer_names,\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "                                                              \n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "print(\"-\" * 60)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)\n",
    "# Save frozen graph to disk\n",
    "\n",
    "for node in graph_def.node:\n",
    "    node.ClearField('experimental_type')\n",
    "    \n",
    "tf.io.write_graph(graph_or_graph_def=graph_def,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pb\",\n",
    "                  as_text=False)\n",
    "# Save its text representation\n",
    "tf.io.write_graph(graph_or_graph_def=graph_def,\n",
    "                  logdir=frozen_out_path,\n",
    "                  name=f\"{frozen_graph_filename}.pbtxt\",\n",
    "                  as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "OUTPUT_DIR = \".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\"\n",
    "PATH_TO_SAVED_MODEL= OUTPUT_DIR + \"\\\\saved_model\"\n",
    "\n",
    "\n",
    "# load the saved model\n",
    "model = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "# Get the model's concrete function\n",
    "concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "\n",
    "# Get the graph definition from the concrete function's graph\n",
    "graph_def = concrete_func.graph.as_graph_def()\n",
    "\n",
    "\n",
    "# save the graph definition\n",
    "tf.io.write_graph(graph_def, '.', 'my_graph_def.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ceeb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from re import match\n",
    "import pyperclip\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "OUTPUT_DIR = \".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\"\n",
    "PATH_TO_SAVED_MODEL= OUTPUT_DIR + \"\\\\saved_model\"\n",
    "\n",
    "input_graph=PATH_TO_SAVED_MODEL + \"\\\\saved_model.pb\"\n",
    "\n",
    "loaded = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "# checkpoint = tf.train.Checkpoint(model=loaded)\n",
    "\n",
    "# checkpoint.save(input_checkpoint)\n",
    "\n",
    "infer = loaded.signatures['serving_default']\n",
    "\n",
    "\n",
    "output_names = [node.op.name for node in infer.outputs]\n",
    "\n",
    "print(\"Output nodes:\")\n",
    "print(output_names)\n",
    "\n",
    "\n",
    "command_name = os.path.abspath(\".\\\\tenserflow_env_py3.9\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\tools\\\\freeze_graph.py\")\n",
    "input_checkpoint= os.path.abspath(OUTPUT_DIR + \"\\\\checkpoint\\\\ckpt-0\")\n",
    "output_node_names = \",\".join(output_names)\n",
    "output_graph = \"frozen_graph_rezult.pb\"\n",
    "input_saved_model_dir = PATH_TO_SAVED_MODEL\n",
    "\n",
    "# output_node_names = \"StatefulPartitionedCall,NoOp,Const_30,saver_filename,StatefulPartitionedCall_1,StatefulPartitionedCall_2\"\n",
    "# input_graph = 'frozen_graph.pb'\n",
    "command = \"python \\\"{}\\\" --input_graph=\\\"{}\\\" --input_binary=True --input_checkpoint=\\\"{}\\\" --output_graph=\\\"{}\\\" --output_node_names=\\\"{}\\\" --input_saved_model_dir=\\\"{}\\\"\".format(command_name, input_graph, input_checkpoint, output_graph, output_node_names, input_saved_model_dir)\n",
    "\n",
    "print(command)\n",
    "\n",
    "pyperclip.copy(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46401a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from re import match\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "OUTPUT_DIR = \".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\exports_2023-04-21_09-40-31\"\n",
    "PATH_TO_SAVED_MODEL= OUTPUT_DIR + \"\\\\saved_model\"\n",
    "\n",
    "loaded = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "infer = loaded.signatures['serving_default']\n",
    "\n",
    "f = tf.function(infer).get_concrete_function(input_tensor=tf.TensorSpec(shape=[1, None, None, 3], dtype=tf.uint8))\n",
    "f2 = convert_variables_to_constants_v2(f)\n",
    "graph_def = f2.graph.as_graph_def()\n",
    "\n",
    "\n",
    "#regex with input and output keyword\n",
    "#print([n.name for n in graph_def.node])\n",
    "\n",
    "extract_names = lambda x: x.name\n",
    "\n",
    "# fara input_control_node si output_control_node\n",
    "input_layers = list(filter(lambda v: match('.*input.*', v.name) and 'input_control_node' not in v.name, graph_def.node))\n",
    "\n",
    "output_layers = list(filter(lambda v: match('.*output.*', v.name) and 'output_control_node' not in v.name, graph_def.node))\n",
    "\n",
    "input_layer_names = list(map(extract_names, input_layers))\n",
    "output_layer_names = list(map(extract_names, output_layers))\n",
    "\n",
    "print(\"Input layers: \")\n",
    "print([n for n in input_layer_names])\n",
    "print(\"Output layers: \")\n",
    "print([n for n in output_layer_names])\n",
    "\n",
    "# # Remove NoOp nodes\n",
    "# for i in reversed(range(len(graph_def.node))):\n",
    "#     if graph_def.node[i].op == 'NoOp':\n",
    "#         del graph_def.node[i]\n",
    "\n",
    "# for node in graph_def.node:\n",
    "#     for i in reversed(range(len(node.input))):\n",
    "#         if node.input[i][0] == '^':\n",
    "#             del node.input[i]\n",
    "\n",
    "\n",
    "# #change the nodes in here \n",
    "# # Remove a lot of Identity nodes\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              input_layer_names,\n",
    "                                                              output_layer_names,\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "                                                           \n",
    "# Export frozen graph\n",
    "with tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:\n",
    "   f.write(graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f339bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.io.gfile.GFile('frozen_graph.pb', \"rb\") as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Restore the graph\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "     # Open a file for writing\n",
    "    with open('debug_output.txt', 'w') as file:\n",
    "        # Write the names of all the operations in the graph to the file\n",
    "        for op in tf.compat.v1.get_default_graph().get_operations():\n",
    "            file.write(op.name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the TensorFlow model\n",
    "model = cv2.dnn.readNetFromTensorflow('frozen_graph_rezult.pb')\n",
    "\n",
    "image = cv2.imread(\".\\\\test.jpg\")\n",
    "# Set the input layer of the model\n",
    "model.setInput(cv2.dnn.blobFromImage(image, size=(300, 300), swapRB=True))\n",
    "\n",
    "# Perform forward pass on the model\n",
    "output = model.forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenserflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
