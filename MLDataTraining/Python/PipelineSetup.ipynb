{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a916b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_label_map(label_map, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for id, name in label_map.items():\n",
    "            f.write('item {\\n')\n",
    "            f.write('  id: {}\\n'.format(id))\n",
    "            f.write(\"  name: '{}'\\n\".format(name))\n",
    "            f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683d9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    1: 'Car',\n",
    "    2: 'Truck'\n",
    "}\n",
    "\n",
    "write_label_map(label_map, '.\\\\training_data\\\\labels\\\\coco_labels.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6dfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping images to test\n",
    "from PIL import Image\n",
    "\n",
    "def crop_image(image_name: str, xmin: int, ymin: int, xmax: int, ymax: int):\n",
    "    # Load the image\n",
    "    image_path = \".\\\\training_data\\\\object-detection-crowdai\\\\\" + image_name\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Define the bounding box\n",
    "    bbox = (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    # Crop the image using the bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(\".\\\\invalid_cropped_images\\\\\" + image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98beacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV TO COCO JSON\n",
    "import csv\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "csv_file = '.\\\\training_data\\\\labels\\\\labels.csv'\n",
    "json_file = '.\\\\training_data\\\\labels\\\\coco.json'\n",
    "\n",
    "ignore_labels = [\"Pedestrian\"]\n",
    "# Define the categories\n",
    "categories = [\n",
    "    {'id': 1, 'name': 'Car'},\n",
    "    {'id': 2, 'name': 'Truck'}\n",
    "]\n",
    "\n",
    "# Initialize the data dictionary\n",
    "data = {'images': [], 'annotations': [], 'categories': categories}\n",
    "\n",
    "# Read the CSV file and add annotations to the data dictionary\n",
    "with open(csv_file, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    counter = 1  # Initialize the counter variable\n",
    "    for row in reader:\n",
    "        if row[\"Label\"] in ignore_labels:\n",
    "            continue\n",
    "        \n",
    "        image_id = int(row['Frame'].split('.')[0])\n",
    "        category_id = 0\n",
    "        for category in categories:\n",
    "            if row['Label'] == category['name']:\n",
    "                category_id = category['id']\n",
    "                break\n",
    "\n",
    "        annotation = {\n",
    "            'id': counter,\n",
    "            'image_id': image_id,\n",
    "            'category_id': category_id,\n",
    "            'bbox': [int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])],\n",
    "            'area': ((int(row['xmax']) - int(row['xmin'])) * (int(row['ymax']) - int(row['ymin']))),\n",
    "            \"iscrowd\": 0\n",
    "        }\n",
    "        \n",
    "        # if annotation['area'] < 0:\n",
    "        #     crop_image(row['Frame'], int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax']))\n",
    "\n",
    "        data['annotations'].append(annotation)\n",
    "        counter +=1\n",
    "\n",
    "# Add the images to the data dictionary\n",
    "for annotation in data['annotations']:\n",
    "    if annotation['image_id'] not in [image['id'] for image in data['images']]:\n",
    "        \n",
    "        # image = Image.open('.\\\\training_data\\\\object-detection-crowdai\\\\' + str(annotation['image_id']) + '.jpg')\n",
    "        # width, height = image.size\n",
    "        \n",
    "        data['images'].append({\n",
    "            'id': annotation['image_id'],\n",
    "            'file_name': str(annotation['image_id']) + '.jpg',\n",
    "            'height': 1200, # Replace with the actual height of your images\n",
    "            'width': 1920 # Replace with the actual width of your images\n",
    "        })\n",
    "\n",
    "# Save the data dictionary as JSON\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b33bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run protoc to setup tenserflow repo\n",
    "!protoc .\\object_detection\\protos\\*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ab3d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command copied to clipboard.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pyperclip\n",
    "\n",
    "train_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\object-detection-crowdai'\n",
    "val_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\object-detection-crowdai'\n",
    "test_image_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\object-detection-crowdai'\n",
    "train_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\coco.json'\n",
    "val_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\coco.json'\n",
    "testdev_annotations_file = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\coco.json'\n",
    "output_dir = '..\\\\..\\\\..\\\\..\\\\..\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\setup_files'\n",
    "label_map_path = '..\\\\..\\\\..\\\\..\\\\..\\\\training_data\\\\labels\\\\coco_labels.pbtxt'\n",
    "\n",
    "cmd = [\n",
    "    'python', 'create_coco_tf_record.py', '--logtostderr', \n",
    "    f'--train_image_dir={train_image_dir}', \n",
    "    f'--val_image_dir={val_image_dir}',\n",
    "    f'--test_image_dir={test_image_dir}',\n",
    "    f'--train_annotations_file={train_annotations_file}',\n",
    "    f'--val_annotations_file={val_annotations_file}',\n",
    "    f'--testdev_annotations_file={testdev_annotations_file}',\n",
    "    f'--output_dir={output_dir}',\n",
    "    f'--label_map_path={label_map_path}'\n",
    "]\n",
    "\n",
    "cmd = f\"python create_coco_tf_record.py --logtostderr --train_image_dir=\\\"{train_image_dir}\\\" --val_image_dir=\\\"{val_image_dir}\\\" --test_image_dir=\\\"{test_image_dir}\\\" --train_annotations_file=\\\"{train_annotations_file}\\\" --val_annotations_file=\\\"{val_annotations_file}\\\" --testdev_annotations_file=\\\"{testdev_annotations_file}\\\" --output_dir=\\\"{output_dir}\\\" --label_map_path=\\\"{label_map_path}\\\"\"\n",
    "\n",
    "pyperclip.copy(cmd)\n",
    "print('Command copied to clipboard.')\n",
    "\n",
    "# subprocess.call(\".\\\\tenserflow_env\\\\Scripts\\\\activate.bat && \" + cmd, shell=True)\n",
    "# result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# if result.returncode == 0:\n",
    "#     print(result.stdout)\n",
    "# else:\n",
    "#     print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f547cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mihai Gherghinescu\\source\\repos\\TrafficManager\\MLDataTraining\\Python\\models\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\setup_files\n",
      "<_MapDataset element_spec={'image/object/bbox/xmax': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/xmin': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/ymax': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/bbox/ymin': SparseTensorSpec(TensorShape([None]), tf.float32), 'image/object/class/label': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/class/text': SparseTensorSpec(TensorShape([None]), tf.string), 'image/object/difficult': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/is_crowd': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/truncated': SparseTensorSpec(TensorShape([None]), tf.int64), 'image/object/view': SparseTensorSpec(TensorShape([None]), tf.string), 'image/encoded': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/filename': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/format': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/height': TensorSpec(shape=(), dtype=tf.int64, name=None), 'image/source_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'image/width': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "#merge coco record files\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def extract_data(record):\n",
    "    feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "        'image/object/is_crowd': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(record, feature_description)\n",
    "    return example\n",
    "\n",
    "# Define a function to write each record to the output file\n",
    "def write_to_tfrecord(example):\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        writer.write(tf.io.serialize_tensor(example))\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# os.chdir(\".\\\\models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\setup_files\\\\\")\n",
    "\n",
    "nr  = 50 # to be changed base on the number of tfrecords you have\n",
    "\n",
    "# List all the sharded files\n",
    "shard_filenames = ['coco_testdev.record-0000{}-of-000{}'.format(i, nr) for i in range(nr)]\n",
    "\n",
    "# Load the dataset from the sharded files\n",
    "dataset = tf.data.TFRecordDataset(shard_filenames).map(extract_data)\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "# Define the output path for the combined .tfrecord file\n",
    "output_path = 'coco_testdev.tfrecord'\n",
    "\n",
    "\n",
    "# Map the dataset to the write function to create the output file\n",
    "#dataset.map(write_to_tfrecord)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c48c9e6a",
   "metadata": {},
   "source": [
    "To check if CUDA and cuDNN installed the right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfef735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenserflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
